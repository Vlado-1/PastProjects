{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sacred-hypothesis",
   "metadata": {},
   "source": [
    "# <center>Workload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-outdoors",
   "metadata": {},
   "source": [
    "### <center>Find the top 5 users with similar interest as a given user id.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-employment",
   "metadata": {},
   "source": [
    "Key points about the problem:\n",
    "* The given user id can be an arbitrary user id (in this case chosen to be = 2955789098).\n",
    "* Users with 'simialr interests' likely reply/retweet to the same kind of tweets.\n",
    "* User interests can be represented as a vector (t1, t2, t2, ..., tn) of IDs of tweets that they reply/retweet to.\n",
    "* Note: if the user replies and retweets to the same tweet, it appears twice in the vector.\n",
    "* Use TF-IDF and Word2Vec to extract the features of the user vectors.\n",
    "* Use cosine similarity to compare all transformed vectors to the given users transformed vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continuing-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broad-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Workload 1 - top 5 similar interests\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "path = \"./tweets.json\"\n",
    "tweets = spark.read.json(path, multiLine=True)\n",
    "\n",
    "# Drop unecessary columns\n",
    "tweets = tweets.drop(\"created_at\")\n",
    "tweets = tweets.drop(\"hash_tags\")\n",
    "tweets = tweets.drop(\"text\")\n",
    "tweets = tweets.drop(\"user_mentions\")\n",
    "tweets = tweets.drop(\"replyto_user_id\")\n",
    "tweets = tweets.drop(\"retweet_user_id\")\n",
    "tweets = tweets.drop(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-moment",
   "metadata": {},
   "source": [
    "### 1.0 Creating Document Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "activated-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document representation tabel\n",
    "\n",
    "def seqFunc(accumulatedDocRep, currentUser):\n",
    "    \n",
    "    replyto_id, retweet_id = currentUser\n",
    "    \n",
    "    if (replyto_id != None):\n",
    "        accumulatedDocRep += str(replyto_id) + \" \"\n",
    "    if (retweet_id != None):\n",
    "        accumulatedDocRep += str(retweet_id) + \" \"\n",
    "            \n",
    "    return accumulatedDocRep\n",
    "\n",
    "def combFunc(accumulatedDocRep1, accumulatedDocRep2):\n",
    "\n",
    "    combinedDocRep = accumulatedDocRep1 + accumulatedDocRep2\n",
    "    return combinedDocRep\n",
    "\n",
    "tweets_rdd = tweets.rdd.map(lambda rec: (rec[2], (rec[0], rec[1])) ) # (uid, (replyid, retweetid))\n",
    "tweets_rdd = tweets_rdd.aggregateByKey(\"\", seqFunc, combFunc, numPartitions=10)\n",
    "\n",
    "# Filter out users that have null replyto_id and retweet_id\n",
    "tweets_rdd = tweets_rdd.filter(lambda rec: len(rec[1])>0)\n",
    "\n",
    "# Convert back to table to perform ML\n",
    "schema = [\"UID\", \"Doc_Rep\"]\n",
    "newTweets = spark.createDataFrame(tweets_rdd, schema)\n",
    "#newTweets.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-willow",
   "metadata": {},
   "source": [
    "### 2.0 Feature extraction with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intensive-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform TF-IDF transformation on document representations\n",
    "tokenizer = Tokenizer(inputCol=\"Doc_Rep\", outputCol=\"tokens\")\n",
    "hashingTF = HashingTF(inputCol=\"tokens\", outputCol=\"tf_transform\", numFeatures=300)\n",
    "idf = IDF(inputCol=\"tf_transform\", outputCol=\"tf_idf_transform\")\n",
    "\n",
    "\n",
    "tokensData = tokenizer.transform(newTweets)\n",
    "featurizedData = hashingTF.transform(tokensData)\n",
    "\n",
    "idfModel = idf.fit(featurizedData)\n",
    "featurized_Tweets = idfModel.transform(featurizedData).drop(\"tf_transform\")\n",
    "#featurized_Tweets.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-workplace",
   "metadata": {},
   "source": [
    "### 3.0 Feature extraction with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "furnished-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Word2Vec feature extraction\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=0, inputCol=\"tokens\", outputCol=\"w2v_transform\")\n",
    "model = word2Vec.fit(featurized_Tweets)\n",
    "featurized_Tweets = model.transform(featurized_Tweets).drop(\"tokens\")\n",
    "#featurized_Tweets.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "traditional-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User to compare against\n",
    "#print(\"Similar to user id: \", 2955789098)\n",
    "tf_idf_v = featurized_Tweets.select(\"UID\", \"tf_idf_transform\").filter(\"UID == 2955789098\").collect()[0][1]\n",
    "#print(\"TF_IDF: \", tf_idf_v)\n",
    "w2v_v = featurized_Tweets.select(\"UID\", \"w2v_transform\").filter(\"UID == 2955789098\").collect()[0][1]\n",
    "#print(\"Word2Vector: \", w2v_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-central",
   "metadata": {},
   "source": [
    "### 4.0 Get top 5 similar users with TF-IDF and Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fleet-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|          top_5_UID|similarity_tf_idf|\n",
      "+-------------------+-----------------+\n",
      "|           17799542|              1.0|\n",
      "|           18368682|              1.0|\n",
      "|          340730132|              1.0|\n",
      "|1361205933695664132|              1.0|\n",
      "|1161398602452918272|              1.0|\n",
      "+-------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+------------------+\n",
      "|          top_5_UID|    similarity_w2v|\n",
      "+-------------------+------------------+\n",
      "|1041094174127411200|1.0000000000000002|\n",
      "| 984155546352865280|1.0000000000000002|\n",
      "|           66806060|1.0000000000000002|\n",
      "|           48363570|1.0000000000000002|\n",
      "|1366007352730603520|1.0000000000000002|\n",
      "+-------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating top 5 similar users for tf_idf feature extraction\n",
    "schema = [\"top_5_UID\", \"Doc_Rep\", \"tf_idf_transform\", \"w2v_transform\", \"similarity_tf_idf\", \"similarity_w2v\"]\n",
    "\n",
    "def cosine_similarity(rec):\n",
    "    \n",
    "    vec1 = rec[\"tf_idf_transform\"]\n",
    "    vec2 = tf_idf_v\n",
    "    \n",
    "    dot_prod = vec1.dot(vec2)\n",
    "    l1 = vec1.dot(vec1)\n",
    "    l2 = vec2.dot(vec2)\n",
    "    \n",
    "    similarity_tf_df = float(dot_prod/(math.sqrt(l1)*math.sqrt(l2)))\n",
    "    \n",
    "    vec1 = rec[\"w2v_transform\"]\n",
    "    vec2 = w2v_v\n",
    "        \n",
    "    dot_prod = vec1.dot(vec2)\n",
    "    l1 = vec1.dot(vec1)\n",
    "    l2 = vec2.dot(vec2)\n",
    "    \n",
    "    similarity_w2v = float(dot_prod/(math.sqrt(l1)*math.sqrt(l2)))\n",
    "    \n",
    "    if (rec[0] != 2955789098):    \n",
    "        return [rec[0], rec[1], rec[2], rec[3], similarity_tf_df, similarity_w2v] \n",
    "    else:\n",
    "        return [rec[0], rec[1], rec[2], rec[3], float(-1.0), float(-1.0)]\n",
    "\n",
    "featurized_Tweets_rdd = featurized_Tweets.rdd.map(cosine_similarity)\n",
    "featurized_Tweets_similarity = spark.createDataFrame(featurized_Tweets_rdd, schema).cache()\n",
    "\n",
    "featurized_Tweets_similarity.sort(featurized_Tweets_similarity.similarity_tf_idf.desc()).select(\"top_5_UID\", \"similarity_tf_idf\").show(5)\n",
    "featurized_Tweets_similarity.sort(featurized_Tweets_similarity.similarity_w2v.desc()).select(\"top_5_UID\", \"similarity_w2v\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "solved-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
